<p>
<div align="center">

# Transformer From Scratch [Python]
</div>
</p>

<p align="center" width="100%">
    <img src="./Transformer From Scratch/Assets/Transformer_Diagram.png" width="40%" height="40%" />
</p>

<div align="center">
    <a>
        <img src="https://img.shields.io/badge/Made%20with-Jupyter-white?style=for-the-badge&logo=Jupyter&logoColor=white">
    </a>
    <a>
        <img src="https://img.shields.io/badge/Made%20with-Python-white?style=for-the-badge&logo=Python&logoColor=white">
    </a>
</div>

<br/>

<div align="center">
    <a href="https://github.com/EstevesX10/Transformer-From-Scratch/blob/main/LICENSE">
        <img src="https://img.shields.io/github/license/EstevesX10/Transformer-From-Scratch?style=flat&logo=gitbook&logoColor=white&label=License&color=white">
    </a>
    <a href="">
        <img src="https://img.shields.io/github/repo-size/EstevesX10/Transformer-From-Scratch?style=flat&logo=googlecloudstorage&logoColor=white&logoSize=auto&label=Repository%20Size&color=white">
    </a>
    <a href="">
        <img src="https://img.shields.io/github/stars/EstevesX10/Transformer-From-Scratch?style=flat&logo=adafruit&logoColor=white&logoSize=auto&label=Stars&color=white">
    </a>
    <a href="https://github.com/EstevesX10/Transformer-From-Scratch/blob/main/DEPENDENCIES.md">
        <img src="https://img.shields.io/badge/Dependencies-DEPENDENCIES.md-white?style=flat&logo=anaconda&logoColor=white&logoSize=auto&color=white"> 
    </a>
</div>

## Project Overview

> ADD PROJECT OVERVIEW

## What are Transformers?

Transformer Models are a type of deep learning model designed to process sequences of data. Their innovative use of attention mechanisms, combined their efficiency has made them a cornerstone of modern NLP applications.

They are capable of:

- Understanding context better than previous models
- Perform Translation Tasks allowing for a easier global communication
- Create Art, Music and even Stories
- Being powerful virtual assistants for smarter interactions

<div align="center">
<img src="./Transformer From Scratch/Assets/Transformer.png" width="60%" height="60%" />
</div>

## How Transformers Work

Transformers break down text/sentences into smaller pieces called `tokens`. Therefore, through the use of attention mechanisms, they are capable of better understanding the relationships between these tokens. Consequently, in translation tasks, they manage to generate a translation (new text) by predicting one word at a time.

<div align="center">
<img src="./Transformer From Scratch/Assets/Translation_Task.png" width="60%" height="60%" />
</div>

## Components of a Transformer

- **Embeddings**: Convert words into numerical vectors
- **Attention Heads**: Focus on different parts of the input
- **Encoder and Decoder**: Process and generate text through Layers
- **Multi-Head Attention**: Enhances the understanding of complex text
- **Feed-Forward Networks**: Refines text Predictions

## Technical Aspects

Transformers commonly use:

- **Data Augmentation**: AI allows to generate synthetic data which allows to fill gaps within setences
- **Active Learning**: Engage AI tp request human feedback on ambiguous cases, improving accuracy
- **Automated Pipelines**: Use of continuous cleaning processes that adapt and learn over time

<div align="right">
<sub>
<!-- <sup></sup> -->

`README.md by Gon√ßalo Esteves`
</sub>
</div>
