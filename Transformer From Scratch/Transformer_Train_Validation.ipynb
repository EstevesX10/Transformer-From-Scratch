{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4241c04c-27f4-41d0-8769-14944d5d5121",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "---\n",
    "# Transformer from Scractch [Python]\n",
    "---\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c238d489-7b52-41c9-b8ff-805e8a6de149",
   "metadata": {},
   "source": [
    "This Notebook mainly focuses on Trainning the Transformer (Perform Translation Tasks) as well as to Validate and Test it's performance upon new instances of data (Unseen Data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d5b5a-e655-4307-bbb3-e17d5cee1a97",
   "metadata": {},
   "source": [
    "---\n",
    "## Train\n",
    "\n",
    "The developed Transformer is going to be used within Translation Tasks between English and Portuguese using the HuggingFace upos dataset for both Train and Validation Steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73aedf89-dc2a-418e-a330-71cd518544dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Importing Dependencies\n",
    "import warnings\n",
    "import torch\n",
    "from torch import (nn)\n",
    "from Configuration import (Get_Configuration, Get_Weights_File_Path)\n",
    "from Train import (Train_Model, Get_Model, Get_Dataset)\n",
    "from Validation import (Run_Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "784c4ac8-3356-4990-b7d4-84459c792e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "config = Get_Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00ca96a-bc00-461a-a581-8bf2f88ea8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_Model(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a80850-bc9b-4490-8d16-3b384a74e017",
   "metadata": {},
   "source": [
    "---\n",
    "## Test / Validation\n",
    "\n",
    "Now, let's take a look on how the Model performs to translate new instances / texts, i.e, let's perform inference with the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22e7c874-6621-40a9-8b50-da6cc9c8927e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n",
      "Max Length of Source Sentence: 204\n",
      "Max Length of Target Sentence: 196\n"
     ]
    }
   ],
   "source": [
    "# Define the Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using Device: {device}\")\n",
    "# config = Get_Configuration()\n",
    "train_dataloader, test_dataloader, tokenizer_source, tokenizer_target = Get_Dataset(config)\n",
    "model = Get_Model(config, tokenizer_source.get_vocab_size(), tokenizer_target.get_vocab_size()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2406bb92-ac96-463a-9405-6a43af3bfcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pretrained Model\n",
    "model_filename = Get_Weights_File_Path(config, f\"19\")\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98870d3-a931-42b5-bebb-a593d32fce80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'I've read that in some book, but I don't remember where.'\n",
      "TARGET: \"Eu li isso em algum livro, mas não me lembro onde.\"\n",
      "PREDICTED: , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Would you tell me,' said Alice, a little timidly, 'why you are painting those roses?'\n",
      "TARGET: \"Vocês me diriam\" disse Alice, um pouco timidamente, \"porque estão a pintar essas rosas?\"\n",
      "PREDICTED: , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Perhaps it doesn't understand English,' thought Alice; 'I daresay it's a French mouse, come over with William the Conqueror.' (For, with all her knowledge of history, Alice had no very clear notion how long ago anything had happened.)\n",
      "TARGET: \"Talvez ele não entenda inglês\", pensou Alice; \"Imagino que ele seja um rato francês, que veio para cá com Guilherme, o Conquistador\" (Pois, com todo o conhecimento dela sobre História, Alice não tinha uma noção clara de há quanto tempo qualquer coisa tinha acontecido).\n",
      "PREDICTED: , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Nothing whatever,' said Alice.\n",
      "TARGET: \"Absolutamente nada\", disse Alice.\n",
      "PREDICTED: , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: She is such a dear quiet thing,' Alice went on, half to herself, as she swam lazily about in the pool, 'and she sits purring so nicely by the fire, licking her paws and washing her face--and she is such a nice soft thing to nurse--and she's such a capital one for catching mice--oh, I beg your pardon!' cried Alice again, for this time the Mouse was bristling all over, and she felt certain it must be really offended. 'We won't talk about her any more if you'd rather not.'\n",
      "TARGET: Ela é uma coisa tão quieta\", Alice continuou, em parte para si mesma, enquanto nadava preguiçosamente na lagoa, \"ela senta-se ronronando tão agradavelmente junto à lareira, lambendo suas patas e lavando a face -— e ela é uma coisa tão fofa de se cuidar — e ela é excelente para pegar ratos -— oh, perdoe-me!\", gritou Alice novamente, pois dessa vez o Rato estava se arrepiando todo e ela teve certeza de que ele devia estar realmente ofendido. - \"Nós não falaremos mais nela se você preferir\".\n",
      "PREDICTED: , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n"
     ]
    }
   ],
   "source": [
    "# Run Validation\n",
    "Run_Validation(model, test_dataloader,\n",
    "               tokenizer_source, tokenizer_target,\n",
    "               config['sequence_length'], device, lambda msg: print(msg), 0, None, num_examples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
