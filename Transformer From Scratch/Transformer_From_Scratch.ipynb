{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4241c04c-27f4-41d0-8769-14944d5d5121",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "---\n",
    "# Transformer from Scratch [Python]\n",
    "---\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c238d489-7b52-41c9-b8ff-805e8a6de149",
   "metadata": {},
   "source": [
    "This Notebook mainly focuses on Trainning the Transformer (Perform Translation Tasks) as well as to Validate and Test it's performance upon new instances of data (Unseen Data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d5b5a-e655-4307-bbb3-e17d5cee1a97",
   "metadata": {},
   "source": [
    "---\n",
    "## Train\n",
    "\n",
    "The developed Transformer is going to be used within Translation Tasks between English and Portuguese using the HuggingFace `opus_books` dataset for both Train and Test / Validation Steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aedf89-dc2a-418e-a330-71cd518544dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Importing Dependencies\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import (nn)\n",
    "from Transformer.Model import (Transformer)\n",
    "from Transformer.Configuration import (Get_Configuration, Get_Weights_File_Path)\n",
    "from Transformer.Train import (Train_Model, Get_Model, Get_Dataset)\n",
    "from Transformer.Validation import (Greedy_Decode, Run_Validation)\n",
    "from Transformer.AttentionVisualization import (Load_Next_Batch, Get_All_Attention_Maps)\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784c4ac8-3356-4990-b7d4-84459c792e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the Pytorch Warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Loading the Configuration Dictionary\n",
    "config = Get_Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ca96a-bc00-461a-a581-8bf2f88ea8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "Train_Model(config, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a80850-bc9b-4490-8d16-3b384a74e017",
   "metadata": {},
   "source": [
    "---\n",
    "## Test / Validation\n",
    "\n",
    "Now, let's take a look on how the Model performs translating new instances / texts, i.e., let's perform inference with the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7c874-6621-40a9-8b50-da6cc9c8927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using Device: {device}\")\n",
    "# config = Get_Configuration()\n",
    "train_dataloader, test_dataloader, tokenizer_source, tokenizer_target = Get_Dataset(config)\n",
    "model = Get_Model(config, tokenizer_source.get_vocab_size(), tokenizer_target.get_vocab_size()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406bb92-ac96-463a-9405-6a43af3bfcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Pretrained Model\n",
    "model_filename = Get_Weights_File_Path(config, f\"100\")\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98870d3-a931-42b5-bebb-a593d32fce80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Validation\n",
    "Run_Validation(model, test_dataloader,\n",
    "               tokenizer_source, tokenizer_target,\n",
    "               config['sequence_length'], device, lambda msg: print(msg), 0, None, num_examples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19e4320-97df-4d20-a026-c675317a6328",
   "metadata": {},
   "source": [
    "---\n",
    "## Attention Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d7695-f312-4cec-a0d9-3020a6289860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Model\n",
    "train_dataloader, test_dataloader, vocabulary_source, vocabulary_target = Get_Dataset(config)\n",
    "model = Get_Model(config, vocabulary_source.get_vocab_size(), vocabulary_target.get_vocab_size()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec7460-5f4e-46cd-93dd-6281946c21c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Pretrained Model\n",
    "model_filename = Get_Weights_File_Path(config, f\"100\")\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b0f75a-4c76-475d-b5e7-e80ffd7f63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Sentence\n",
    "batch, encoder_input_tokens, decoder_input_tokens = Load_Next_Batch(config, model, test_dataloader,\n",
    "                                                                    vocabulary_source, vocabulary_target,\n",
    "                                                                    device)\n",
    "print(f'[SOURCE]: {batch[\"source_text\"]}')\n",
    "print(f'[TARGET]: {batch[\"target_text\"]}')\n",
    "\n",
    "# Calculate the Sentence Length\n",
    "sentence_length = encoder_input_tokens.index('[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29f799-6f02-4087-84a7-05c7cd47ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layers and heads to which we want to visualize the Attention\n",
    "layers = [0, 1, 2]\n",
    "heads = [0, 1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918bc44-464a-4f4c-99e0-1b7a379bff50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the Encoder Self-Attention\n",
    "Get_All_Attention_Maps(model, \"encoder\", layers, heads, encoder_input_tokens, encoder_input_tokens, min(20, sentence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e128c2b9-408a-4ae1-8f6e-045ffae752cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the Decoder Self-Attention\n",
    "Get_All_Attention_Maps(model, \"decoder\", layers, heads, decoder_input_tokens, decoder_input_tokens, min(20, sentence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332093b3-e054-4684-9094-13d55f4d6db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's take a look into the Cross Attention [Where the translation task happens]\n",
    "Get_All_Attention_Maps(model, \"encoder-decoder\", layers, heads, encoder_input_tokens, decoder_input_tokens, min(20, sentence_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29661431-0abe-4b9c-a5e4-7f286068a696",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
